{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import base64\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils import experiment_to_prompt\n",
    "from utils import round_to_significant_figures\n",
    "from img_utils import hash_image, decode_base64_and_plot\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_noisy_line(seed, \n",
    "                               num_points=50, \n",
    "                               base_noise_scale=0.1, \n",
    "                               box_size=10):\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    def random_point_on_box(side, box_size=10):\n",
    "        if side == 'left':\n",
    "            x = 0\n",
    "            y = np.random.uniform(0, box_size)\n",
    "        elif side == 'right':\n",
    "            x = box_size\n",
    "            y = np.random.uniform(0, box_size)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid side: {side}\")\n",
    "        return np.array([x, y])\n",
    "\n",
    "    # Choose two random endpoints inside the box\n",
    "    p0 = random_point_on_box('left', box_size)\n",
    "    p1 = random_point_on_box('right',box_size)\n",
    "    \n",
    "    # Create a straight line between p0 and p1\n",
    "    t = np.linspace(0, 1, num_points)\n",
    "    line = np.outer(1 - t, p0) + np.outer(t, p1)\n",
    "\n",
    "    # Compute slope\n",
    "    dx = p1[0] - p0[0]\n",
    "    dy = p1[1] - p0[1]\n",
    "\n",
    "    slope = dy / dx\n",
    "\n",
    "    slope_factor = np.arctan(np.abs(slope)) / (np.pi / 2)  # Normalize between 0 and 1\n",
    "    noise_scale = base_noise_scale * slope_factor\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(scale=noise_scale, size=line.shape)\n",
    "    noisy_line = line + noise\n",
    "    \n",
    "    # Clip to stay within bounds if needed\n",
    "    noisy_line = np.clip(noisy_line, 0, box_size)\n",
    "\n",
    "    # # pick a random point in the line\n",
    "    # random_index = np.random.randint(0, num_points)\n",
    "\n",
    "    # # calculate the range of the y-values\n",
    "    # y_range = np.max(noisy_line[:, 1]) - np.min(noisy_line[:, 1])\n",
    "\n",
    "    # sign = np.random.choice([-1, 1])\n",
    "    # noisy_line[random_index, 1] += sign * range_coeff * y_range\n",
    "\n",
    "    return noisy_line\n",
    "\n",
    "def get_jackknife_residuals(x, y):\n",
    "    \"\"\"\n",
    "    Compute jackknife (leave-one-out) residuals for linear regression of y on x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like, shape (n,)\n",
    "        Predictor values.\n",
    "    y : array_like, shape (n,)\n",
    "        Response values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    r_loo : ndarray, shape (n,)\n",
    "        The jackknife residuals, i.e. e_i / (1 - h_ii), where\n",
    "        e_i = y_i - Å·_i is the ordinary residual and h_ii is the leverage.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    if x.ndim != 1 or y.ndim != 1:\n",
    "        raise ValueError(\"x and y must both be one-dimensional arrays\")\n",
    "    if x.size != y.size:\n",
    "        raise ValueError(\"x and y must have the same length\")\n",
    "\n",
    "    n = x.size\n",
    "    # Design matrix with intercept\n",
    "    X = np.column_stack((np.ones(n), x))\n",
    "\n",
    "    # Compute (X'X)^{-1} X'y  and hat-matrix diagonal\n",
    "    XtX_inv = np.linalg.inv(X.T @ X)\n",
    "    beta = XtX_inv @ (X.T @ y)\n",
    "    hat_diag = np.einsum('ij,ji->i', X, XtX_inv @ X.T)  # h_ii\n",
    "\n",
    "    # Fitted values and ordinary residuals\n",
    "    y_hat = X @ beta\n",
    "    resid = y - y_hat\n",
    "\n",
    "    # Jackknife (leave-one-out) residuals\n",
    "    r_loo = resid / (1.0 - hat_diag)\n",
    "\n",
    "    return r_loo\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def get_outlier_line(line, seed, threshold=3.0, step_size=0.25, max_iter=10000):\n",
    "    # 1) generate your base line+noise:\n",
    "\n",
    "    output = line.copy()\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 2) pick one random point to turn into an outlier\n",
    "    idx = np.random.randint(0, output.shape[0])\n",
    "\n",
    "    # 3) compute its jackknife residual\n",
    "    resid = get_jackknife_residuals(output[:,0], output[:,1])[idx]\n",
    "\n",
    "    i = 0\n",
    "    while abs(resid) < threshold and i < max_iter:\n",
    "        i += 1\n",
    "        # move in the *same* direction as the residual: \n",
    "        #   if resid > 0, push upward; if resid < 0, push downward\n",
    "        direction = np.sign(resid)\n",
    "        if direction == 0:\n",
    "            # if it happens to be exactly zero, pick a random direction\n",
    "            direction = np.random.choice([-1, 1])\n",
    "\n",
    "        output[idx, 1] += step_size * direction\n",
    "\n",
    "        # recompute the jackknife residual for that point\n",
    "        resid = get_jackknife_residuals(output[:,0], output[:,1])[idx]\n",
    "\n",
    "    if abs(resid) < threshold:\n",
    "        raise RuntimeError(f\"Failed to exceed |resid|={threshold} after {max_iter} steps\")\n",
    "    return output, idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resids(x, y):\n",
    "    x = sm.add_constant(x)\n",
    "    model = sm.OLS(y, x).fit() \n",
    "    influence = model.get_influence()\n",
    "    standardized_residuals = influence.resid_studentized_internal\n",
    "    return standardized_residuals\n",
    "\n",
    "# calculate z score in y direction\n",
    "def get_z_score(df, idx):\n",
    "    outlier_x = df['x'][idx]\n",
    "    outlier_y = df['y'][idx]\n",
    "\n",
    "    z_score_x = (outlier_x - df['x'].mean()) / df['x'].std()\n",
    "    z_score_y = (outlier_y - df['y'].mean()) / df['y'].std()\n",
    "    return z_score_x, z_score_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_image(df):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    # Save the figure to an in-memory bytes buffer in PNG format\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)  # Close the figure to free resources\n",
    "    buf.seek(0)     # Rewind the buffer to the beginning\n",
    "\n",
    "    # Convert the image in the buffer to a base64 encoded string\n",
    "    img_bytes = buf.getvalue()\n",
    "    img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "\n",
    "    return img_base64\n",
    "\n",
    "def unhash_image(img_base64):\n",
    "\n",
    "    # decode pic_hash to png\n",
    "    # Step 1: Decode the base64 hash back to bytes\n",
    "    pic_bytes = base64.b64decode(img_base64)\n",
    "\n",
    "    # Step 2: Convert bytes to an image using PIL\n",
    "    image = Image.open(io.BytesIO(pic_bytes))\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data generation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "output = generate_random_noisy_line(seed=seed, \n",
    "                                    num_points=20, \n",
    "                                    base_noise_scale=0.3, \n",
    "                                    box_size=10)\n",
    "\n",
    "new_line_less_noise, idx = get_outlier_line(output,\n",
    "                                    seed=seed, \n",
    "                                    threshold=1.5, \n",
    "                                    step_size=0.1, \n",
    "                                    max_iter=10000)\n",
    "\n",
    "new_line, idx = get_outlier_line(output,\n",
    "                                    seed=seed, \n",
    "                                    threshold=2.5, \n",
    "                                    step_size=0.1, \n",
    "                                    max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(output[:, 0], output[:, 1])\n",
    "plt.scatter(new_line[:, 0], new_line[:, 1])\n",
    "plt.scatter(new_line_less_noise[:, 0], new_line_less_noise[:, 1])\n",
    "plt.scatter\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['x', 'y', 'img_b64', 'z_score_y', 'z_score_x', 'scale', 'outlier', 'outlier_idx', 'original_index', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scale in [1, 100, 10000]:\n",
    "    for type in ['true', 'misleading']:\n",
    "        for seed in range(100):\n",
    "\n",
    "            np.random.seed(seed)\n",
    "\n",
    "            output = generate_random_noisy_line(seed=seed, \n",
    "                                                num_points=20, \n",
    "                                                base_noise_scale=0.3, \n",
    "                                                box_size=10)\n",
    "            \n",
    "            new_line, idx = get_outlier_line(output,\n",
    "                                                seed=seed, \n",
    "                                                threshold=2.5, \n",
    "                                                step_size=0.1, \n",
    "                                                max_iter=10000)\n",
    "            \n",
    "            misleading_df = pd.DataFrame(output, columns=['x', 'y'])\n",
    "            df = pd.DataFrame(new_line, columns=['x', 'y'])\n",
    "\n",
    "            for el in [df, misleading_df]:\n",
    "                el['x'] = el['x'] * scale\n",
    "                el['y'] = el['y'] * scale\n",
    "\n",
    "                el['x'] = round_to_significant_figures(el['x'], 4)\n",
    "                el['y'] = round_to_significant_figures(el['y'], 4)\n",
    "\n",
    "            outlier = (df['x'][idx], df['y'][idx])\n",
    "            z_score_x, z_score_y = get_z_score(df, idx)\n",
    "\n",
    "            img_b64 = hash_image(df) if type == 'true' else hash_image(misleading_df)\n",
    "\n",
    "            df = df.sample(frac=1).reset_index()\n",
    "            to_add = {\n",
    "                'x': [df['x'].tolist()],\n",
    "                'y': [df['y'].tolist()],\n",
    "                'img_b64': img_b64,\n",
    "                'z_score_y': z_score_y,\n",
    "                'z_score_x': z_score_x,\n",
    "                'scale': scale,\n",
    "                'outlier' : [outlier],\n",
    "                'outlier_idx': idx,\n",
    "                'original_index': [df['index'].tolist()],\n",
    "                'type': type\n",
    "            }\n",
    "            final_df = pd.concat([final_df, pd.DataFrame(to_add)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "final_df.to_csv('input_dataframe.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_base64_and_plot(base64_str, name=None, save=True):\n",
    "    # # Decode the base64 string\n",
    "    # img_data = base64.b64decode(base64_str)\n",
    "\n",
    "    # # Create a BytesIO object from the decoded data\n",
    "    # img_buffer = io.BytesIO(img_data)\n",
    "\n",
    "    # # Read the image from the buffer and display it\n",
    "    # img = plt.imread(img_buffer)\n",
    "    # plt.imshow(img)\n",
    "    # plt.axis('off')  # Hide axes\n",
    "    # plt.show()\n",
    "    # if save: \n",
    "    #     # plt.tight_layout()\n",
    "    #     # Save the image to a file\n",
    "    #     fig.savefig('images/cluster_ex.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Decode the base64 string\n",
    "    img_data = base64.b64decode(base64_str)\n",
    "\n",
    "    # Create a BytesIO object from the decoded data\n",
    "    img_buffer = io.BytesIO(img_data)\n",
    "\n",
    "    # Read the image from the buffer\n",
    "    img = plt.imread(img_buffer)\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # Hide axes\n",
    "\n",
    "    if save:\n",
    "        # Save the image to a file, create the file if it doesn't exist\n",
    "        if not os.path.exists('images'):\n",
    "            os.makedirs('images')\n",
    "        fig.savefig(f'images/{name}.pdf', dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from img_utils import decode_base64_and_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set dpi to 300 through rcparams\n",
    "plt.rcParams['figure.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " decode_base64_and_plot(final_df.iloc[101]['img_b64'], name='deceptive_outlier_plot', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_base64_and_plot(final_df.iloc[1]['img_b64'], name='outlier_plot', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(final_df.iloc[0]['x'], final_df.iloc[0]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 10x10 grid of plots\n",
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axes[i, j].scatter(df_lst[i * 10 + j]['x'], df_lst[i * 10 + j]['y'])\n",
    "        # set x and y limits to 0-10\n",
    "        axes[i, j].set_xlim(0, 10)\n",
    "        axes[i, j].set_ylim(-5, 10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkscapital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
