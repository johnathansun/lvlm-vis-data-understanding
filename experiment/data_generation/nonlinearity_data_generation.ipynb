{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "import io \n",
    "import base64\n",
    "from PIL import Image\n",
    "from ast import literal_eval\n",
    "import sys\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "\n",
    "J_PATH = True\n",
    "if J_PATH: \n",
    "    BASE = \"/Users/johnathansun/Documents/\"\n",
    "else: \n",
    "    BASE = \"/Users/victoriali/Documents/GitHub/\"\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils import experiment_to_prompt\n",
    "from utils import round_to_significant_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_parabolas(total_points, extra_points, seed):\n",
    "    \"\"\"\n",
    "    Generate sample points along a downward-opening parabola y = -a x^2 + b x.\n",
    "    Samples are uniformly spaced in x from 0 to x_max such that\n",
    "    - The vertex at x_v = b/(2a) falls on the (total_points - extra_points)-th point (0-indexed).\n",
    "    - There are extra_points samples beyond the vertex.\n",
    "\n",
    "    Parameters:\n",
    "    total_points (int): Total number of (x, y) pairs to return.\n",
    "    extra_points (int): Number of points beyond the vertex.\n",
    "\n",
    "    Returns:\n",
    "    x (np.ndarray): Array of x-values, shape (total_points,).\n",
    "    y (np.ndarray): Array of y-values, shape (total_points,).\n",
    "    \"\"\"\n",
    "    # Random parabola parameters\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    a = np.random.uniform(0, 1)\n",
    "    b = np.random.uniform(0, 10)\n",
    "\n",
    "    # Compute the vertex location\n",
    "    x_vertex = b / (2 * a)\n",
    "\n",
    "    if extra_points >= total_points:\n",
    "        raise ValueError(\"extra_points must be less than total_points\")\n",
    "\n",
    "    # Determine the index (0-based) at which the vertex should occur\n",
    "    idx_vertex = total_points - extra_points - 1\n",
    "\n",
    "    # Compute maximum x so that idx_vertex corresponds exactly to x_vertex\n",
    "    x_max = x_vertex * (total_points - 1) / idx_vertex\n",
    "\n",
    "    # Generate uniformly spaced x-values\n",
    "    x = np.linspace(0, x_max, total_points)\n",
    "    y = -a * x**2 + b * x\n",
    "\n",
    "    x_offset = np.random.uniform(0, 10)\n",
    "    y_offset = np.random.uniform(0, 10)\n",
    "\n",
    "    x_noise = np.random.normal(0, np.mean(x) / 150, len(x))\n",
    "    y_noise = np.random.normal(0, np.mean(y) / 150, len(y))\n",
    "\n",
    "    x += x_offset + x_noise\n",
    "    y += y_offset + y_noise\n",
    "\n",
    "    params = {\n",
    "        'a' : a,\n",
    "        'b' : b,\n",
    "        'x_offset' : x_offset,\n",
    "        'y_offset' : y_offset,\n",
    "        'x_noise' : x_noise,\n",
    "        'y_noise' : y_noise\n",
    "    }\n",
    "\n",
    "    return x, y, params\n",
    "\n",
    "\n",
    "def hash_image(df):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    # Save the figure to an in-memory bytes buffer in PNG format\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)  # Close the figure to free resources\n",
    "    buf.seek(0)     # Rewind the buffer to the beginning\n",
    "\n",
    "    # Convert the image in the buffer to a base64 encoded string\n",
    "    img_bytes = buf.getvalue()\n",
    "    img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "\n",
    "    return img_base64\n",
    "\n",
    "def unhash_image(img_base64):\n",
    "\n",
    "    # decode pic_hash to png\n",
    "    # Step 1: Decode the base64 hash back to bytes\n",
    "    pic_bytes = base64.b64decode(img_base64)\n",
    "\n",
    "    # Step 2: Convert bytes to an image using PIL\n",
    "    image = Image.open(io.BytesIO(pic_bytes))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deceptive_nonlinearity(x, y, y_noise, seed=None):\n",
    "    \"\"\"\n",
    "    Fit a straight line to (x, y), then return x and the\n",
    "    model’s predictions perturbed by a little Gaussian noise.\n",
    "    \"\"\"\n",
    "    # make sure we’re working with numpy arrays\n",
    "    x = np.asarray(x).flatten()\n",
    "    y = np.asarray(y).flatten()\n",
    "\n",
    "    # reproducible noise\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # design matrix with intercept\n",
    "    X = sm.add_constant(x)           # shape (n_samples, 2)\n",
    "\n",
    "    # fit OLS: endog=y, exog=X\n",
    "    model   = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "\n",
    "    # get clean predictions\n",
    "    y_pred = results.predict(X)      # intercept + slope*x\n",
    "\n",
    "    y_noisy = y_pred + y_noise\n",
    "\n",
    "    return x, y_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "\n",
    "for i in range(100):\n",
    "    # choose randomly between 3 5 7 and 9\n",
    "    # extra_points = np.random.choice([3, 5, 7, 9])\n",
    "    extra_points = 9\n",
    "    x, y, y_noise = generate_parabolas(20, extra_points, i)\n",
    "    x, y_deceptive = generate_deceptive_nonlinearity(x, y, y_noise, i)\n",
    "    df_lst.append(pd.DataFrame({'x': x, 'y': y, 'y_deceptive': y_deceptive}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in 10x10 grid\n",
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.scatter(df_lst[i]['x'], df_lst[i]['y'])\n",
    "    ax.scatter(df_lst[i]['x'], df_lst[i]['y_deceptive'])\n",
    "    ax.set_title(f'Parabola {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.suptitle('Extra Points = 9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['x', 'y', 'img_b64', 'img_deceptive', 'extra_points', 'params', 'seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scale in [1, 100, 10000]:\n",
    "\n",
    "seed = 0\n",
    "scale = 1\n",
    "\n",
    "for extra_points in [3, 5, 7, 9]:\n",
    "    for _ in range(100):\n",
    "\n",
    "        total_points = 20\n",
    "\n",
    "        x, y, params = generate_parabolas(total_points, extra_points, seed)\n",
    "\n",
    "        df = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "        y_noise = params['y_noise']\n",
    "        x, y_deceptive = generate_deceptive_nonlinearity(x, y, y_noise, seed)\n",
    "\n",
    "        seed += 1\n",
    "\n",
    "        deceptive_df = pd.DataFrame({'x': x, 'y': y_deceptive})\n",
    "\n",
    "        for el in [df, deceptive_df]:\n",
    "            el['x'] = el['x'] * scale\n",
    "            el['y'] = el['y'] * scale\n",
    "            el['x'] = round_to_significant_figures(el['x'], 4)\n",
    "            el['y'] = round_to_significant_figures(el['y'], 4)\n",
    "        \n",
    "        to_add = {\n",
    "            'x': [df['x'].tolist()],\n",
    "            'y': [df['y'].tolist()],\n",
    "            'img_b64': hash_image(df),\n",
    "            'img_deceptive': hash_image(deceptive_df),\n",
    "            'extra_points': extra_points,\n",
    "            'params': [params],\n",
    "            'scale': scale,\n",
    "            'seed': seed\n",
    "        }\n",
    "\n",
    "        final_df = pd.concat([final_df, pd.DataFrame(to_add)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('input_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = final_df[final_df['extra_points'] == 3].iloc[8]\n",
    "unhash_image(test_row['img_b64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhash_image(test_row['img_deceptive'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkscapital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
