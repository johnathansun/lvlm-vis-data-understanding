{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import base64\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from utils import experiment_to_prompt\n",
    "from img_utils import hash_image, decode_base64_and_plot\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_2d_clusters_min_linkage(\n",
    "    n_clusters: int,\n",
    "    points_per_cluster: int,\n",
    "    min_linkage_dist: float,\n",
    "    cluster_std: float = 1.0,\n",
    "    x_range: tuple = (-10, 10),\n",
    "    y_range: tuple = (-10, 10),\n",
    "    max_tries: int = 1000,\n",
    "    random_state: int = None\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generate 2D Gaussian clusters such that the minimum distance\n",
    "    between any two points in different clusters is >= min_linkage_dist.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_clusters : int\n",
    "        Number of clusters.\n",
    "    points_per_cluster : int\n",
    "        Number of points in each cluster.\n",
    "    min_linkage_dist : float\n",
    "        The required minimum distance between any two points in different clusters.\n",
    "    cluster_std : float\n",
    "        Standard deviation of each Gaussian cluster.\n",
    "    x_range : (float, float)\n",
    "        Range for the x-coordinate of cluster centers.\n",
    "    y_range : (float, float)\n",
    "        Range for the y-coordinate of cluster centers.\n",
    "    max_tries : int\n",
    "        How many times to retry sampling before giving up.\n",
    "    random_state : int, optional\n",
    "        Seed for reproducibility.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : ndarray, shape (n_clusters * points_per_cluster, 2)\n",
    "        The sampled points.\n",
    "    y : ndarray, shape (n_clusters * points_per_cluster,)\n",
    "        Integer labels (0…n_clusters-1) of which cluster each point belongs to.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    RuntimeError\n",
    "        If it fails to meet the linkage criterion after `max_tries` attempts.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    x_min, x_max = x_range\n",
    "    y_min, y_max = y_range\n",
    "\n",
    "    for attempt in range(1, max_tries + 1):\n",
    "        # 1) Sample cluster centers uniformly\n",
    "        centers = rng.uniform([x_min, y_min], [x_max, y_max], size=(n_clusters, 2))\n",
    "\n",
    "        # 2) Generate points for each cluster\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        for i, c in enumerate(centers):\n",
    "            pts = rng.normal(loc=c, scale=cluster_std, size=(points_per_cluster, 2))\n",
    "            X_list.append(pts)\n",
    "            y_list.append(np.full(points_per_cluster, i, dtype=int))\n",
    "        X = np.vstack(X_list)\n",
    "        y = np.concatenate(y_list)\n",
    "\n",
    "        # 3) Check single-linkage (min inter-cluster distance)\n",
    "        #    We only need to look at pairs from different clusters.\n",
    "        #    As soon as we find a violation, we break and retry.\n",
    "        violation = False\n",
    "        for i in range(len(X)):\n",
    "            for j in range(i+1, len(X)):\n",
    "                if y[i] != y[j]:\n",
    "                    if np.linalg.norm(X[i] - X[j]) < min_linkage_dist:\n",
    "                        violation = True\n",
    "                        break\n",
    "            if violation:\n",
    "                break\n",
    "\n",
    "        if not violation:\n",
    "            return X, y, centers\n",
    "\n",
    "    raise RuntimeError(\n",
    "        f\"Failed to generate clusters with min linkage ≥ {min_linkage_dist} \"\n",
    "        f\"after {max_tries} attempts.\"\n",
    "    )\n",
    "\n",
    "def hash_image(df):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(df['x'], df['y'])\n",
    "\n",
    "    # Save the figure to an in-memory bytes buffer in PNG format\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)  # Close the figure to free resources\n",
    "    buf.seek(0)     # Rewind the buffer to the beginning\n",
    "\n",
    "    # Convert the image in the buffer to a base64 encoded string\n",
    "    img_bytes = buf.getvalue()\n",
    "    img_base64 = base64.b64encode(img_bytes).decode('utf-8')\n",
    "\n",
    "    return img_base64\n",
    "\n",
    "def unhash_image(img_base64):\n",
    "\n",
    "    # decode pic_hash to png\n",
    "    # Step 1: Decode the base64 hash back to bytes\n",
    "    pic_bytes = base64.b64decode(img_base64)\n",
    "\n",
    "    # Step 2: Convert bytes to an image using PIL\n",
    "    image = Image.open(io.BytesIO(pic_bytes))\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample points at least n units apart within a unit square\n",
    "\n",
    "def sample_points(n, min_dist):\n",
    "    points = []\n",
    "    while len(points) < n:\n",
    "        point = np.random.rand(2) * 10\n",
    "        if all(np.linalg.norm(point - p, ord=2) >= min_dist for p in points):\n",
    "            points.append(point)\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_from_sklean(data):\n",
    "    return pd.DataFrame(data[0], columns=['x', 'y'])\n",
    "\n",
    "def ez_prompt(df):\n",
    "    data_str = experiment_to_prompt(df['x'], df['y'])\n",
    "    return data_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, centers = generate_2d_clusters_min_linkage(\n",
    "        n_clusters=3,\n",
    "        points_per_cluster=20,\n",
    "        min_linkage_dist=3,\n",
    "        cluster_std=0.5,\n",
    "        x_range=(0, 10),\n",
    "        y_range=(0, 10),\n",
    "        random_state=4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_misleading_clusters(centers, seed, n_points):\n",
    "    np.random.seed(seed)\n",
    "    # get mean of centers\n",
    "    mean_center = np.mean(centers, axis=0)\n",
    "    # get distance between mean and each center\n",
    "    distances = np.linalg.norm(centers - mean_center, axis=1)\n",
    "    # get index of center with largest distance\n",
    "    std = np.max(distances) / 2\n",
    "    # generate points around mean center\n",
    "    X = np.random.normal(mean_center, std, (n_points, 2))\n",
    "    # generate labels\n",
    "    y = np.zeros(n_points)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lst = []\n",
    "deceptive_df_lst = []\n",
    "for i in range(100):\n",
    "    X, y, centers = generate_2d_clusters_min_linkage(\n",
    "        n_clusters=3,\n",
    "        points_per_cluster=20,\n",
    "        min_linkage_dist=3,\n",
    "        cluster_std=0.5,\n",
    "        x_range=(0, 10),\n",
    "        y_range=(0, 10),\n",
    "        random_state=i\n",
    "    )\n",
    "    df = pd.DataFrame(X, columns=['x', 'y'])\n",
    "    df_lst.append(df)\n",
    "\n",
    "    X_deceptive, y_deceptive = generate_misleading_clusters(centers, i, 120)\n",
    "    deceptive_df = pd.DataFrame(X_deceptive, columns=['x', 'y'])\n",
    "    deceptive_df_lst.append(deceptive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot in 10x10 grid, deceptive_df_lst on top of df_lst\n",
    "fig, axes = plt.subplots(10, 10, figsize=(20, 20))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    ax.scatter(deceptive_df_lst[i]['x'], deceptive_df_lst[i]['y'])\n",
    "    # ax.scatter(df_lst[i]['x'], df_lst[i]['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import round_to_significant_figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(columns=['x', 'y', 'img_b64', 'img_deceptive', 'num_clusters', 'points_per_cluster', 'scale', 'seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for scale in [1, 100, 10000]:\n",
    "\n",
    "scale = 1\n",
    "seed = 0\n",
    "\n",
    "for _ in range(100):\n",
    "    for num_clusters in [2, 3, 4, 5]:\n",
    "\n",
    "        total_points = 120\n",
    "        points_per_cluster = total_points // num_clusters\n",
    "\n",
    "        X, y, centers = generate_2d_clusters_min_linkage(\n",
    "            n_clusters=num_clusters,\n",
    "            points_per_cluster=points_per_cluster,\n",
    "            min_linkage_dist=2,\n",
    "            cluster_std=0.6,\n",
    "            x_range=(0, 10),\n",
    "            y_range=(0, 10),\n",
    "            random_state=seed,\n",
    "            max_tries = 5000\n",
    "        )\n",
    "\n",
    "        df = pd.DataFrame(X, columns=['x', 'y'])\n",
    "        # shuffle rows\n",
    "        df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        X_deceptive, y_deceptive = generate_misleading_clusters(centers, seed, total_points)\n",
    "        deceptive_df = pd.DataFrame(X_deceptive, columns=['x', 'y'])\n",
    "\n",
    "        seed += 1\n",
    "\n",
    "        for el in [df, deceptive_df]:\n",
    "            el['x'] = el['x'] * scale\n",
    "            el['y'] = el['y'] * scale\n",
    "            el['x'] = round_to_significant_figures(el['x'], 4)\n",
    "            el['y'] = round_to_significant_figures(el['y'], 4)\n",
    "        \n",
    "        to_add = {\n",
    "            'x': [df['x'].tolist()],\n",
    "            'y': [df['y'].tolist()],\n",
    "            'img_b64': hash_image(df),\n",
    "            'img_deceptive': hash_image(deceptive_df),\n",
    "            'num_clusters': num_clusters,\n",
    "            'points_per_cluster': points_per_cluster,\n",
    "            'scale': scale,\n",
    "            'seed': seed\n",
    "        }\n",
    "\n",
    "\n",
    "        final_df = pd.concat([final_df, pd.DataFrame(to_add)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.scatter(final_df.iloc[i]['x'], final_df.iloc[i]['y'])\n",
    "plt.scatter(final_df.iloc[i+1]['x'], final_df.iloc[i+1]['y'])\n",
    "plt.scatter(final_df.iloc[i+2]['x'], final_df.iloc[i+2]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(final_df['x'].value_counts().reset_index()['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('input_dataframe.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = final_df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhash_image(example['img_b64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unhash_image(example['img_deceptive'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hkscapital",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
